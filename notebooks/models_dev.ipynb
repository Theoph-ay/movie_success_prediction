{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946171c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.13.2)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/HP/Desktop/UI/important/Data Science/movie-success-prediction/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Installing initial libraries, others will be installed as we go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b97e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataframe\n",
    "path = r\"C:\\Users\\HP\\Desktop\\UI\\important\\Data Science\\movie-success-prediction\\data\\processed\\cleaned_movies_data.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c437153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that because I am using a cleaned data, I do not need this datacleaner function, but if the data is not, then you may need it\n",
    "#you can refer to the data_cleaning notebook to see the data cleaning process and maybe why\n",
    "#Tranformer for data cleaning (I'd not include it in my pipeline)\n",
    "#dependong on your data or what you want to do, you may need to drop duplicates with subset =\"name\" and/or dropna on ratings outside this function\n",
    "#Or depending on what you want, you can use SimpleImputer() to put mean or median or mode, also, make_pipeline to include multiple pipelines\n",
    "#I dropped na because the rows without values actually do not have any values on the site and they were very small i think 5 entries(not very significant)\n",
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    #BaseEstimator allows you use functions like get_params, set_params, TransformerMixin allows fit and transform\n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything from the data, so we just return self.\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Make a copy to avoid changing the original data\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        # --- Apply cleaning functions from your notebook ---\n",
    "\n",
    "        # 1. Clean vote_count\n",
    "        def clean_vote(val):\n",
    "            if isinstance(val, str):\n",
    "                val = val.lower().strip()\n",
    "                if \"k\" in val:\n",
    "                    return int(float(val.replace(\"k\", \"\")) * 1000)\n",
    "                elif \"m\" in val:\n",
    "                    return int(float(val.replace(\"m\", \"\")) * 1_000_000)\n",
    "                else:\n",
    "                    return int(float(val))\n",
    "            return val\n",
    "        \n",
    "        if 'vote_count' in X_copy.columns:\n",
    "            X_copy['vote_count'] = X_copy['vote_count'].apply(clean_vote)\n",
    "\n",
    "        # 2. Clean movie_duration\n",
    "        def clean_duration(val):\n",
    "            if isinstance(val, str):\n",
    "                hours = 0\n",
    "                minutes = 0\n",
    "                h_match = re.search(r\"(\\d+)\\s*h\", val.lower())\n",
    "                if h_match:\n",
    "                    hours = int(h_match.group(1))\n",
    "                m_match = re.search(r\"(\\d+)\\s*m\", val.lower())\n",
    "                if m_match:\n",
    "                    minutes = int(m_match.group(1))\n",
    "                return hours * 60 + minutes\n",
    "            return val\n",
    "            \n",
    "        if 'movie_duration' in X_copy.columns:\n",
    "            X_copy['movie_duration'] = X_copy['movie_duration'].apply(clean_duration).astype(float)\n",
    "\n",
    "        # 3. Drop rows with zero movie_duration\n",
    "        if 'movie_duration' in X_copy.columns:\n",
    "             X_copy = X_copy[X_copy['movie_duration'] > 0]\n",
    "\n",
    "        # 4. Drop rows with 'Metascore' in movie_certification\n",
    "        if 'movie_certification' in X_copy.columns:\n",
    "            X_copy = X_copy[~X_copy['movie_certification'].str.contains(\"Metascore\", na=False)]\n",
    "            \n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f13e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Features X and Y\n",
    "X = df.drop(\"ratings\", axis=1)\n",
    "y = df[\"ratings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42) \n",
    "#0.25 to set 25% of the data as test and random_state to make sure we get the same results every time we run the code 42 is just a number, could be any other number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f54e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column groups for pipeline\n",
    "num_features = ['year', 'vote_count', 'movie_duration']\n",
    "cat_features = ['genre', 'movie_certification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1798ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "    (\"num\", StandardScaler(), num_features), #scaler helps to avoid large numbers that can skew the data\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features)\n",
    "    ],\n",
    "    remainder=\"drop\" #This will drop the name and imdb_id columns that are not specified\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a linear regression model\n",
    "lin_model = LinearRegression(n_jobs= -1)\n",
    "lin_reg = Pipeline(steps =[\n",
    "    ('preprocessor', preprocessor),\n",
    "    (\"regressor\", lin_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a277a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabefbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model with pickle\n",
    "import pickle\n",
    "path = r\"C:\\Users\\HP\\Desktop\\UI\\important\\Data Science\\movie-success-prediction\\models\"\n",
    "with open (path + \"lin_reg.pickle\", \"wb\") as to_write:\n",
    "    pickle.dump(lin_reg, to_write)\n",
    "\n",
    "#The model is saved as lin_reg.pickle in the models folder, I should comment out the saving and the fit part, but the model didnt take long to train so I won't comment it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the saved model\n",
    "with open (path + \"lin_reg.pickle\", \"rb\") as to_read:\n",
    "    lin_reg = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on test set\n",
    "y_pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regressor model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg = Pipeline(steps =[\n",
    "    ('preprocessor', preprocessor),\n",
    "    (\"regressor\", tree_model)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model with decision tree\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tree model\n",
    "with open(path+ \"tree_reg.pickle\", \"wb\") as to_write:\n",
    "    pickle.dump(tree_reg, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f17b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read tree model\n",
    "with open(path+\"tree_reg.pickle\", \"rb\") as to_read:\n",
    "    tree_reg = pickle.load(to_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acfb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict test data\n",
    "y_pred = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "#Model evaluation\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ca3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Models and Ensemble models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_reg = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "(\"randomforestregressor\", rf)\n",
    "])\n",
    "rf_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822fbc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "with open(path+\"rf_reg.pickle\", \"wb\") as to_write:\n",
    "    pickle.dump(rf_reg, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read model\n",
    "with open(path+\"rf_reg.pickle\", \"rb\") as to_read:\n",
    "    rf_reg = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91915a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict with model\n",
    "y_pred = rf_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5325c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "#Model evaluation\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea052f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradientboosting model\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb_reg = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "(\"gradientregressor\", gb)\n",
    "])\n",
    "gb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79c283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "with open(path+\"gb_reg.pickle\", \"wb\") as to_write:\n",
    "    pickle.dump(gb_reg, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read model\n",
    "with open(path+\"gb_reg.pickle\", \"rb\") as to_read:\n",
    "    gb_reg = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict with model\n",
    "y_pred = gb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cf849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "#Model evaluation\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "ab = AdaBoostRegressor(random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
